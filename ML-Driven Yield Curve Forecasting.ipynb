{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76567f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ML-Driven Yield Curve Forecasting\n",
    "\n",
    "This script:\n",
    "    -Loads and cleans yield curve data from Excel files\n",
    "    -Creates features like lagged rates, rolling averages, partial derivatives w.r.t. \n",
    "    time and maturity by modelling a multivariate function from SmoothBivariateSpline\n",
    "    -Trains the Ridge, Random Forest and XGBoost machine learning models\n",
    "    -Makes multi-day forecasts of future yield curves\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad81200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import SmoothBivariateSpline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADING AND CLEANING\n",
    "\n",
    "def combine_dataframes(filename_1 : str, filename_2 : str, sheetName : str, skipRows : int, rename_startcol_1 : str, rename_loopcol_1 : str, rename_startcol_2 : str, rename_loopcol_2 : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combines two Excel files of yield curve data into one dataset.\n",
    "    \n",
    "    The UK yield data is in two separate files with different column names so the column\n",
    "    names are changed and the two datasets are concatenated.\n",
    "    \n",
    "    Args:\n",
    "        filename_1: Path to older Excel file\n",
    "        filename_2: Path to newer Excel file\n",
    "        sheetName: Which sheet to read from both files\n",
    "        skipRows: How many header rows to skip\n",
    "        rename_startcol_1: What the date column is called in file 1\n",
    "        rename_loopcol_1: Pattern for maturity columns in file 1\n",
    "        rename_startcol_2: What the date column is called in file 2\n",
    "        rename_loopcol_2: Pattern for maturity columns in file 2\n",
    "        \n",
    "    Returns:\n",
    "        Combined dataframe with clearer column names\n",
    "    \"\"\"\n",
    "    \n",
    "    #Read the Excel files\n",
    "    data_1 = pd.read_excel(filename_1, sheet_name=sheetName, skiprows=skipRows)\n",
    "    data_2 = pd.read_excel(filename_2, sheet_name=sheetName, skiprows=skipRows)\n",
    "\n",
    "    #Rename the specified columns to 'Date'\n",
    "    data_1.rename(columns={rename_startcol_1: 'Date'}, inplace=True)\n",
    "    data_2.rename(columns={rename_startcol_2: 'Date'}, inplace=True)\n",
    "\n",
    "    #Rename columns in a loop based on the starting substring\n",
    "    i = 0\n",
    "    for col in data_1.columns:\n",
    "        if col.startswith(rename_loopcol_1):\n",
    "            data_1.rename(columns={col: f\"{i / 2:.1f}\"}, inplace=True)\n",
    "        i += 1\n",
    "    j = 0\n",
    "    for col in data_2.columns:\n",
    "        if col.startswith(rename_loopcol_2):\n",
    "            data_2.rename(columns={col: f\"{j / 2:.1f}\"}, inplace=True)\n",
    "        j += 1\n",
    "    \n",
    "    #Combine the two DataFrames\n",
    "    combined_data = pd.concat([data_1, data_2], ignore_index=True)\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "def clean_up_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean up the raw yield data to make it ready for analysis.\n",
    "    \n",
    "    Converts text dates to proper datetime objects.\n",
    "    Removes rows where the last column has an NaN value because if this value is empty \n",
    "    then the rest of the row is empty.\n",
    "    Gets rid of columns where more than 25% of its values are NaN\n",
    "    \n",
    "    Args:\n",
    "        data: Raw yield curve data with Date column and maturity columns\n",
    "        \n",
    "    Returns:\n",
    "        Clean dataframe with dates as index and no missing data issues\n",
    "    \"\"\"\n",
    "    #Convert 'Date' column to datetime format so that date-based operations can be performed\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    #Now modify so that we can index by date\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    #Remove all rows in last column with NaN values\n",
    "    data.dropna(subset=[data.columns[-1]], inplace=True)\n",
    "\n",
    "    #Decide to either keep or remove first column if more than a quarter of its values are NaN\n",
    "    if (data[data.columns[0]].isna().sum()) / len(data[data.columns[0]]) > 0.25:\n",
    "        data.drop(columns=[data.columns[0]], inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def modify_data_for_modelling(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the DataFrame so that each row is a (time, maturity) -> interest rate point.\n",
    "\n",
    "    Yield curve data is a spreadsheet with dates as rows and maturities as columns.\n",
    "    Converted into individual observations because the machine learning models need this\n",
    "    format.\n",
    "    \n",
    "    Args:\n",
    "        data: Wide format yield data (dates x maturities)\n",
    "        \n",
    "    Returns:\n",
    "        Long format data with columns: Time, Maturity, Rate\n",
    "    \"\"\"\n",
    "    \n",
    "    #Put Date from an index back into a column\n",
    "    data_reset = data.reset_index()\n",
    "\n",
    "    #Remove 'Date' column after resetting index\n",
    "    data_reset.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "    #Find the start time (first date in the dataset) and convert dates to number of days since start date using old data index\n",
    "    start_date = data.index.min()\n",
    "    times = (data.index - start_date).days #Uses data not data_reset because data_reset has lost the date index\n",
    "\n",
    "    #Now insert times as the first column in data_reset\n",
    "    data_reset.insert(loc=0, column='Time', value=times)\n",
    "\n",
    "    #Now melt the DataFrame to long format (make each row a (time, maturity) ↦ interest rate point)\n",
    "    long_data = data_reset.melt(id_vars=['Time'], var_name='Maturity', value_name='Rate')\n",
    "\n",
    "    #Convert 'Maturity' column to float type\n",
    "    long_data['Maturity'] = long_data['Maturity'].astype(float)\n",
    "\n",
    "    return long_data\n",
    "\n",
    "def sort_chronologically(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sorts the data by time then maturity.\n",
    "    \"\"\"\n",
    "    sorted_data = data.sort_values([\"Time\", \"Maturity\"]).copy()\n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1eabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YIELD SURFACE MODELING\n",
    "\n",
    "def model_multivariate_function(values, s: float) -> SmoothBivariateSpline:\n",
    "    \"\"\"\n",
    "    Models a continuous multivariate function of interest rate = f(time, maturity).\n",
    "    \n",
    "    Args:\n",
    "        values: Tuple of (time_points, maturity_points, rate_values)\n",
    "        s: Smoothing factor\n",
    "        \n",
    "    Returns:\n",
    "        A model that can interpolate rates and calculate derivatives\n",
    "    \"\"\"\n",
    "    #Unpack the input tuple\n",
    "    timeValues, maturityValues, rateValues = values\n",
    "\n",
    "    #Create the model using SmoothBivariateSpline\n",
    "    model = SmoothBivariateSpline(timeValues, maturityValues, rateValues, s=s)\n",
    "\n",
    "    return model\n",
    "\n",
    "def test_multivariate_model(model: SmoothBivariateSpline, values) -> None:\n",
    "    \"\"\"\n",
    "    Tests the multivariate model by calculating and printing RMSE and R² metrics.\n",
    "    \"\"\"\n",
    "    #Unpack the input tuple\n",
    "    timeValues, maturityValues, rateValues = values\n",
    "    \n",
    "    #Get the predicted rates from the model\n",
    "    predicted_rates = model.ev(timeValues, maturityValues)\n",
    "\n",
    "    #Calculate RMSE and R²\n",
    "    rmse = np.sqrt(mean_squared_error(rateValues, predicted_rates))\n",
    "    r2 = r2_score(rateValues, predicted_rates)\n",
    "    print(f\"Root Mean Squared Error (RMSE) for multivariate model: {rmse}\")\n",
    "    print(f\"R-squared (R²) for multivariate model: {r2}\")\n",
    "\n",
    "def calculate_partial_derivatives(model: SmoothBivariateSpline, data, first_derivative: str, second_derivative: str):\n",
    "    \"\"\"\n",
    "    Calculates the partial derivatives of the model with respect to time and maturity.\n",
    "\n",
    "    Partial derivative of rate w.r.t. time is added as a feature.\n",
    "    Partial derivative of rate w.r.t. maturity is added as a feature.\n",
    "\n",
    "    Args:\n",
    "    model: Fitted smooth surface\n",
    "    data: Points where we want to calculate derivatives\n",
    "    first_derivative: Column name for time variable\n",
    "    second_derivative: Column name for maturity variable\n",
    "        \n",
    "    Returns:\n",
    "        Two arrays: (time_derivatives, maturity_derivatives)\n",
    "    \"\"\"\n",
    "    #Calculate derivative w.r.t. time\n",
    "    first_partial_derivative = model.ev(\n",
    "        data[first_derivative].values, data[second_derivative].values, dx=1, dy=0 #w.r.t. first variable (time)\n",
    "        )\n",
    "    \n",
    "    #Calculate derivative w.r.t. maturity\n",
    "    second_partial_derivative = model.ev(\n",
    "        data[first_derivative].values, data[second_derivative].values, dx=0, dy=1 #w.r.t. second variable (maturity)\n",
    "    )\n",
    "\n",
    "    return first_partial_derivative, second_partial_derivative\n",
    "\n",
    "def add_partial_derivatives(data: pd.DataFrame, partial_derivatives) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds the calculated partial derivatives as new columns to the original DataFrame.\n",
    "    \"\"\"\n",
    "    #Unpack the input tuple\n",
    "    partial_derivative_time, partial_derivative_maturity = partial_derivatives\n",
    "\n",
    "    #Add the partial derivatives as new columns to the DataFrame\n",
    "    data['Partial_Derivative_Time'] = partial_derivative_time\n",
    "    data['Partial_Derivative_Maturity'] = partial_derivative_maturity\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38083b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING FEATURES FOR MACHINE LEARNING\n",
    "\n",
    "def get_lagged_data(data: pd.DataFrame, lag: int, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a new DataFrame with lagged values of the chosen column by the specified lag.\n",
    "    Lagging is done within each (Time, Maturity) group.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataframe\n",
    "        lag: How many days back to look\n",
    "        column: Which column to create lagged version of\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with new lagged column added\n",
    "    \"\"\"\n",
    "    #Shifts the chosen column by the chosen lag and stores it in a new column\n",
    "    lagged_data = data.copy()\n",
    "    lagged_data[f\"{column}_lag_{lag}\"] = (\n",
    "        lagged_data.groupby([\"Maturity\"])[column].shift(lag)\n",
    "    )\n",
    "    return lagged_data\n",
    "\n",
    "def get_rolling_mean(data: pd.DataFrame, window: int, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a new DataFrame with rolling mean values of the chosen column over \n",
    "    the specified window size.\n",
    "\n",
    "    Helps smooth out daily noise and captures the underlying trend.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataframe\n",
    "        window: How many days to average over\n",
    "        column: Which column to calculate average for\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with new rolling mean column\n",
    "    \"\"\"\n",
    "    rolling_data = data.copy()\n",
    "    rolling_data[f\"{column}_rolling_mean_{window}\"] = (rolling_data.groupby(\"Maturity\")[column].transform(lambda x: x.rolling(window, min_periods=1).mean()).shift(1))\n",
    "    return rolling_data\n",
    "\n",
    "def get_rolling_std(data: pd.DataFrame, window: int, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a new DataFrame with rolling standard deviation values of the \n",
    "    chosen column over the specified window size.\n",
    "\n",
    "    These will be added to the features.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataframe\n",
    "        window: How many days to look at\n",
    "        column: Which column to calculate volatility for\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with new rolling standard deviation column\n",
    "    \"\"\"\n",
    "    rolling_data = data.copy()\n",
    "    rolling_data[f\"{column}_rolling_std_{window}\"] = (rolling_data.groupby(\"Maturity\")[column].transform(lambda x: x.rolling(window, min_periods=2).std()).shift(1))\n",
    "    return rolling_data\n",
    "\n",
    "def remove_na_rows(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes rows with NaN values from the DataFrame.\n",
    "\n",
    "    Some rows will be NaN because of lagged columns.\n",
    "    \"\"\"\n",
    "    cleaned_data = data.dropna().copy()\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e347046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE DATA FOR MACHINE LEARNING\n",
    "\n",
    "def get_X(data: pd.DataFrame, feature_columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the feature columns from the DataFrame to create X.\n",
    "    \"\"\"\n",
    "    X = data[feature_columns].copy()\n",
    "    X_sorted = X.sort_values(\"Time\").copy()\n",
    "    return X_sorted\n",
    "\n",
    "def get_y(data: pd.DataFrame, target_column: str, X_sorted_df : pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extracts the target column from the DataFrame to create y.\n",
    "    \"\"\"\n",
    "    y = data[target_column].copy()\n",
    "    y_sorted = y.loc[X_sorted_df.index].copy()  #y aligned with sorted X\n",
    "    return y_sorted\n",
    "\n",
    "def split_data(X: pd.DataFrame, y: pd.Series, train_size: float) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Splits the feature set X and target variable y into training and testing \n",
    "    sets based on the specified train size.\n",
    "\n",
    "    Splits so that earlier data is used for training and later data is used for testing.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: Target variable\n",
    "        train_size: What fraction to use for training (e.g. 0.8 = 80%)\n",
    "        \n",
    "    Returns:\n",
    "        (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    #Chooses where to split based on the train_size\n",
    "    split_index = int(len(X) * train_size)\n",
    "\n",
    "    #Splits so that model is trained on earlier data and tested on later data\n",
    "    X_train = X.iloc[:split_index].copy()\n",
    "    X_test = X.iloc[split_index:].copy()\n",
    "    y_train = y.iloc[:split_index].copy()\n",
    "    y_test = y.iloc[split_index:].copy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def consistent_indexes(data: pd.DataFrame, X_sorted : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Matches row indices.\n",
    "    \"\"\"\n",
    "    data_consistent = data.loc[X_sorted.index].copy()\n",
    "    return data_consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50007783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACHINE LEARNING MODELS\n",
    "\n",
    "def ridge_regression_model(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, alpha: float):\n",
    "    \"\"\"\n",
    "    Trains a Ridge Regression model using the training feature set X_train and \n",
    "    target variable y_train with the specified alpha.\n",
    "\n",
    "    Tests RMSE and R2 of the model.\n",
    "\n",
    "    Works well with linear relationships.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_test, y_test: Test data  \n",
    "        alpha: Regularization strength (higher = simpler model)\n",
    "        \n",
    "    Returns:\n",
    "        Trained Ridge model\n",
    "    \"\"\"\n",
    "    #Trains model\n",
    "    model = Ridge()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions_ridge = model.predict(X_test)\n",
    "    \n",
    "    #Tests\n",
    "    rmse_ridge = np.sqrt(mean_squared_error(y_test, predictions_ridge))\n",
    "    r2_ridge = r2_score(y_test, predictions_ridge)\n",
    "    print(f\"RMSE for ridge: {rmse_ridge:.6f}, R²: {r2_ridge:.4f}\")\n",
    "    return model\n",
    "\n",
    "def random_forest_regression_model(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, n_estimators: int, random_state: int):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest Regression model using the training feature set X_train and \n",
    "    target variable y_train with the specified number of estimators and random state.\n",
    "\n",
    "    Tests RMSE and R2 of the model.\n",
    "\n",
    "    Works well at capturing non-linear interactions between features.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_test, y_test: Test data\n",
    "        n_estimators: How many trees to build\n",
    "        random_state: Random seed for reproducible results\n",
    "        \n",
    "    Returns:\n",
    "        Trained Random Forest model\n",
    "    \"\"\"\n",
    "    #Trains model\n",
    "    model_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    predictions_rf = model_rf.predict(X_test)\n",
    "\n",
    "    #Tests\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_test, predictions_rf))\n",
    "    r2_rf = r2_score(y_test, predictions_rf)\n",
    "    print(f\"Random Forest RMSE: {rmse_rf:.4f}, R²: {r2_rf:.4f}\")\n",
    "    return model_rf\n",
    "\n",
    "def XGB_boost_model(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, n_estimators: int, learning_rate: float, max_depth: int, random_state: int):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost Regression model using the training feature set X_train and \n",
    "    target variable y_train with the specified parameters.\n",
    "\n",
    "    Tests RMSE and R2 of the model.\n",
    "\n",
    "    Works well with non-linear patterns.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_test, y_test: Test data\n",
    "        n_estimators: How many trees to build\n",
    "        learning_rate: How much each tree contributes\n",
    "        max_depth: How complex individual trees can be\n",
    "        random_state: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Trained XGBoost model\n",
    "    \"\"\"\n",
    "    #Trains model\n",
    "    model_xgb = xgb.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, random_state=random_state)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    predictions_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "    #Tests\n",
    "    rmse_xgb = np.sqrt(mean_squared_error(y_test, predictions_xgb))\n",
    "    r2_xgb = r2_score(y_test, predictions_xgb)\n",
    "    print(f\"RMSE for xgb: {rmse_xgb:.4f}, R²: {r2_xgb:.4f}\")\n",
    "    return model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FULL MODEL TESTING PIPELINE FUNCTIONS\n",
    "\n",
    "def clean_and_set_features(filename_1: str, filename_2: str, sheetName: str):\n",
    "    \"\"\"\n",
    "    Complete data preparation pipeline.\n",
    "    \n",
    "    Runs through all the data cleaning and feature creation steps in the right order.\n",
    "    \n",
    "    Returns:\n",
    "        Clean dataframe with all features ready for machine learning\n",
    "    \"\"\"\n",
    "    #Formats data so that it can be worked on more easily\n",
    "    data = combine_dataframes(filename_1=filename_1, filename_2=filename_2, sheetName=sheetName, skipRows=4, rename_startcol_1='Unnamed: 0', rename_loopcol_1='Unnamed', rename_startcol_2='Refresh', rename_loopcol_2='Refresh')\n",
    "    cleaned_data = clean_up_data(data)\n",
    "    modified_data = modify_data_for_modelling(cleaned_data)\n",
    "    ordered_data = sort_chronologically(modified_data)\n",
    "\n",
    "    #Gets all the lagged rate columns\n",
    "    lagged_data_1 = get_lagged_data(ordered_data, lag=1, column='Rate')\n",
    "    lagged_data_5 = get_lagged_data(lagged_data_1, lag=5, column='Rate')\n",
    "    lagged_data_20 = get_lagged_data(lagged_data_5, lag=20, column='Rate')\n",
    "    lagged_data = lagged_data_20\n",
    "\n",
    "    #Gets the rolling statistics\n",
    "    rolling_mean_data = get_rolling_mean(lagged_data, window=5, column='Rate')\n",
    "    rolling_std_data = get_rolling_std(rolling_mean_data, window=20, column='Rate')\n",
    "\n",
    "    #Removes na rows due to lagged/rolling columns\n",
    "    final_data = remove_na_rows(rolling_std_data)\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def train_and_test_ridge_rf_xgb(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Train and test all three models.\n",
    "    \"\"\"\n",
    "    #Splits data for training/testing machine learning model\n",
    "    X = get_X(data, feature_columns=['Time', 'Maturity', 'Rate_lag_1', 'Rate_lag_5', 'Rate_lag_20', 'Rate_rolling_mean_5', 'Rate_rolling_std_20'])\n",
    "    y = get_y(data, target_column='Rate', X_sorted_df=X)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, train_size=0.8)\n",
    "\n",
    "    #Gets values to model the multivariate function\n",
    "    multivariate_model_values = (\n",
    "        X_train['Time'].values,\n",
    "        X_train['Maturity'].values,\n",
    "        y_train.values\n",
    "    )\n",
    "\n",
    "    #Models the multivariate function\n",
    "    multivariate_model = model_multivariate_function(values=multivariate_model_values, s=len(multivariate_model_values[2])/150) #s found by trial and error\n",
    "    test_multivariate_model(multivariate_model, multivariate_model_values)\n",
    "\n",
    "    #Adds the partial derivative columns to each X_train and X_test\n",
    "    partial_time_train, partial_maturity_train = calculate_partial_derivatives(multivariate_model, X_train, 'Time', 'Maturity')\n",
    "    X_train = add_partial_derivatives(X_train, (partial_time_train, partial_maturity_train))\n",
    "\n",
    "    partial_time_test, partial_maturity_test = calculate_partial_derivatives(multivariate_model, X_test, 'Time', 'Maturity')\n",
    "    X_test = add_partial_derivatives(X_test, (partial_time_test, partial_maturity_test))\n",
    "\n",
    "    #Trains the machine learning models\n",
    "    ridge_model = ridge_regression_model(X_train, y_train, X_test, y_test, alpha=1.0)\n",
    "    rf_model = random_forest_regression_model(X_train, y_train, X_test, y_test, n_estimators=100, random_state=42)\n",
    "    xgb_model = XGB_boost_model(X_train, y_train, X_test, y_test, n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "    return ridge_model, rf_model, xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORECASTING FUNCTIONS\n",
    "\n",
    "def train_models_all_data(data: pd.DataFrame, feature_columns):\n",
    "    \"\"\"\n",
    "    Train models on the full dataset to predict future rates. Returns the models.\n",
    "    \"\"\"\n",
    "    #Gets training values\n",
    "    X = get_X(data, feature_columns)\n",
    "    y = get_y(data, 'Rate', X)\n",
    "\n",
    "    #Trains ridge, random forest and XGBoost\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    ridge_model.fit(X, y)\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    xgb_model.fit(X, y)\n",
    "\n",
    "    return ridge_model, rf_model, xgb_model\n",
    "\n",
    "def create_future_dataframe(past_data: pd.DataFrame, multivariate_model: SmoothBivariateSpline, days_ahead: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Set up a dataframe for making future predictions.\n",
    "    \n",
    "    Creates the features and dataframe needed to predict the next days_ahead days.\n",
    "\n",
    "    Args:\n",
    "        past_data: Historical data to build on\n",
    "        multivariate_model: Smooth surface model\n",
    "        days_ahead: How many days to forecast\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe for forecasting\n",
    "    \"\"\"\n",
    "    #Gets the last time in the past data\n",
    "    last_time = past_data['Time'].max()\n",
    "\n",
    "    #Get the times for the days chosen to be forecasted\n",
    "    future_times = np.array([last_time + i for i in range(1, days_ahead + 1)])\n",
    "\n",
    "    #Keep same maturities as before\n",
    "    maturities = past_data['Maturity'].unique()\n",
    "    \n",
    "    #Creates the dataframe using the future times and the same maturities as before\n",
    "    future_grid = pd.DataFrame([(time, maturity) for time in future_times for maturity in maturities], columns=['Time', 'Maturity'])\n",
    "    future_grid = sort_chronologically(future_grid)\n",
    "\n",
    "    #Create the Predicted Rate column in the new dataframe\n",
    "    future_grid['Predicted_Rate'] = np.nan\n",
    "\n",
    "    #Add the last 20 values from the past data\n",
    "    last_20_times = past_data['Time'].unique()[-20:]\n",
    "    last_20_data = past_data[past_data['Time'].isin(last_20_times)]\n",
    "    last_20_data = sort_chronologically(last_20_data)\n",
    "\n",
    "    last_20_data = last_20_data.rename(columns={\"Rate\": \"Predicted_Rate\"})\n",
    "    future_grid = pd.concat([last_20_data, future_grid], ignore_index=True)\n",
    "    future_grid = sort_chronologically(future_grid)\n",
    "\n",
    "    #Adds the partial derivatives\n",
    "    partial_time_future, partial_maturity_future = calculate_partial_derivatives(multivariate_model, future_grid, 'Time', 'Maturity')\n",
    "    future_grid = add_partial_derivatives(future_grid, (partial_time_future, partial_maturity_future))\n",
    "\n",
    "    return future_grid\n",
    "\n",
    "def predict_next_day_rates(model, future_data: pd.DataFrame, feature_columns: list, day_to_predict: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict rates for one specific day and update lagged features.\n",
    "    \n",
    "    The predicted rates are then added to the lagged rate columns and\n",
    "    rolling statistics to be used as features for the next day.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ML model\n",
    "        future_data: Dataframe with historical context and future periods\n",
    "        feature_columns: Which features the model uses\n",
    "        day_to_predict: Which day (time value) to make predictions for\n",
    "        \n",
    "    Returns:\n",
    "        Updated dataframe with predictions and updated lagged features\n",
    "    \"\"\"\n",
    "    #Extracts the data for the day chosen to predict\n",
    "    current_day_data = future_data[future_data['Time'] == day_to_predict].copy()\n",
    "    \n",
    "    #Generate predictions for all maturities on the day\n",
    "    predicted_rates = model.predict(current_day_data[feature_columns])\n",
    "    \n",
    "    #Store predictions in the main dataframe\n",
    "    prediction_mask = future_data['Time'] == day_to_predict\n",
    "    future_data.loc[prediction_mask, 'Predicted_Rate'] = predicted_rates\n",
    "    \n",
    "    #Update lagged features for the next day\n",
    "    next_day = day_to_predict + 1\n",
    "\n",
    "    #Doesn't add lagged features if at last day\n",
    "    if next_day != future_data['Time'].max() + 1:\n",
    "        for i, predicted_rate in enumerate(predicted_rates):\n",
    "            current_maturity = current_day_data.iloc[i]['Maturity']\n",
    "            next_day_mask = ((future_data['Time'] == next_day) & \n",
    "                            (future_data['Maturity'] == current_maturity))\n",
    "            \n",
    "            if next_day_mask.any():\n",
    "                #Get historical rate data for this maturity up to current day\n",
    "                maturity_history = future_data[\n",
    "                    (future_data['Maturity'] == current_maturity) & \n",
    "                    (future_data['Time'] <= day_to_predict)\n",
    "                ].sort_values('Time')\n",
    "                \n",
    "                #Combine original rates with predicted rates, removing any missing values\n",
    "                combined_rates = maturity_history['Predicted_Rate'].fillna(maturity_history['Predicted_Rate'])\n",
    "                valid_rates = combined_rates.dropna()\n",
    "                \n",
    "                #Update 1-day lag with the rate just predicted\n",
    "                future_data.loc[next_day_mask, 'Rate_lag_1'] = predicted_rate\n",
    "                \n",
    "                #Update 5-day lag and 5-day rolling mean\n",
    "                future_data.loc[next_day_mask, 'Rate_lag_5'] = valid_rates.iloc[-5]\n",
    "                recent_5_rates = valid_rates.iloc[-5:]\n",
    "                future_data.loc[next_day_mask, 'Rate_rolling_mean_5'] = recent_5_rates.mean()\n",
    "                \n",
    "                #Update 20-day lag and 20-day rolling standard deviation\n",
    "                future_data.loc[next_day_mask, 'Rate_lag_20'] = valid_rates.iloc[-20]\n",
    "                recent_20_rates = valid_rates.iloc[-20:]\n",
    "                future_data.loc[next_day_mask, 'Rate_rolling_std_20'] = recent_20_rates.std()\n",
    "        \n",
    "    return future_data\n",
    "\n",
    "def predict_future_rates(ML_model, past_data: pd.DataFrame, future_data: pd.DataFrame, feature_columns, future_days: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts entire dataset by predicting one day at a time.\n",
    "    \n",
    "    Predict day 1, add those predictions to the features of day 2, etc.\n",
    "\n",
    "    Args:\n",
    "        ML_model: Trained machine learning model\n",
    "        past_data: Historical data \n",
    "        future_data: Future periods set up with create_future_dataframe()\n",
    "        feature_columns: List of feature column names\n",
    "        future_days: How many days ahead to predict\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe with predictions for all future days\n",
    "    \"\"\"\n",
    "    #Finds the last time and uses as the first future time\n",
    "    first_future_time = past_data['Time'].max()\n",
    "\n",
    "    #Forecasts all chosen times, adding each forecast to the features of the next prediction\n",
    "    for i in range(0, future_days + 1):\n",
    "        prediction = predict_next_day_rates(ML_model, future_data, feature_columns, day_to_predict=first_future_time + i)\n",
    "        future_data = prediction\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66316aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISPLAY FORECAST\n",
    "\n",
    "def get_clean_forecasts(past_data: pd.DataFrame, forecasted_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts forecasted rates to the original file format.\n",
    "    \"\"\"\n",
    "    #Gets last time in the past data\n",
    "    last_past_time = past_data['Time'].max()\n",
    "\n",
    "    #Gets only future data\n",
    "    future_data = forecasted_data[forecasted_data['Time'] >= last_past_time].copy()\n",
    "    \n",
    "    #Gets correct column name\n",
    "    rate_column = 'Predicted_Rate' if 'Predicted_Rate' in future_data.columns else 'Rate'\n",
    "    \n",
    "    #Convert Time to actual dates starting from Jan 4th 2016 (start of original data)\n",
    "    start_date = pd.to_datetime('2016-01-04')\n",
    "    future_data['Time'] = start_date + pd.to_timedelta(future_data['Time'] - 1, unit='days')\n",
    "    \n",
    "    #Converst maturities to columns\n",
    "    wide_format = future_data.pivot(index='Time', columns='Maturity', values=rate_column)\n",
    "    wide_format.columns.name = None\n",
    "    wide_format.columns = [f\"{col:.1f}\" for col in wide_format.columns]\n",
    "    \n",
    "    #Sorts the columns by increasing maturity\n",
    "    sorted_columns = sorted(wide_format.columns, key=lambda x: float(x))\n",
    "    return wide_format[sorted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4318f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH FORECAST\n",
    "\n",
    "def plot_yield_curve_evolution(clean_forecast, num_curves=6):\n",
    "    \"\"\"\n",
    "    Plot yield curves at different time points to show evolution.\n",
    "    \"\"\"\n",
    "    #Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    #Select evenly spaced dates\n",
    "    dates = clean_forecast.index\n",
    "    step = len(dates) // num_curves\n",
    "    selected_dates = dates[::step][:num_curves]\n",
    "    \n",
    "    #Convert maturity names from string to float\n",
    "    maturities = [float(col) for col in clean_forecast.columns]\n",
    "    \n",
    "    #Plot each date as a separate yield curve\n",
    "    for date in selected_dates:\n",
    "        rates = clean_forecast.loc[date].values\n",
    "        ax.plot(maturities, rates, marker='o', label=date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    #Plot configuration\n",
    "    ax.set_xlabel('Maturity (Years)')\n",
    "    ax.set_ylabel('Interest Rate (%)')\n",
    "    ax.set_title('Forecasted Yield Curve Evolution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_3d_yield_surface(clean_forecast, subsample=10):\n",
    "    \"\"\"\n",
    "    Create 3D surface plot of the yield curve over time.\n",
    "    \"\"\"\n",
    "    #Initialise 3D plot\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    #Subsample data for cleaner visualization\n",
    "    forecast_subset = clean_forecast.iloc[::subsample]\n",
    "    \n",
    "    #Create meshgrid for 3D surface plotting\n",
    "    #Convert dates to numeric format\n",
    "    dates_numeric = mdates.date2num(forecast_subset.index)\n",
    "    maturities = [float(col) for col in forecast_subset.columns]\n",
    "    \n",
    "    #Generate coordinate grids for surface plotting\n",
    "    X, Y = np.meshgrid(dates_numeric, maturities)\n",
    "    Z = forecast_subset.values.T\n",
    "    \n",
    "    #Create 3D surface plot\n",
    "    surface = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
    "    \n",
    "    #Format axes\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Maturity (Years)')\n",
    "    ax.set_zlabel('Interest Rate (%)')\n",
    "    ax.set_title('3D Yield Surface Forecast')\n",
    "    \n",
    "    #Format date axis\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    \n",
    "    #Add colourbar\n",
    "    fig.colorbar(surface, shrink=0.5, aspect=5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_rate_time_series(clean_forecast, selected_maturities=[1.0, 2.0, 5.0, 10.0, 30.0, 40.0]):\n",
    "    \"\"\"\n",
    "    Plot time series for specific maturities.\n",
    "    \"\"\"\n",
    "    #Create figure for time series plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    #Plot each selected maturity as a separate time series line\n",
    "    for maturity in selected_maturities:\n",
    "        col_name = f\"{maturity:.1f}\"\n",
    "        #Check if maturity exists in data before plotting\n",
    "        if col_name in clean_forecast.columns:\n",
    "            ax.plot(clean_forecast.index, clean_forecast[col_name], \n",
    "                   label=f'{maturity}-Year', linewidth=2)\n",
    "    \n",
    "    #Configurations\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Interest Rate (%)')\n",
    "    ax.set_title('Forecasted Interest Rate Time Series by Maturity')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    #Format x-axis dates\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data in a usable format\n",
    "data = clean_and_set_features(\"GLC Nominal daily data_2016 to 2024.xlsx\", \"GLC Nominal daily data_2025 to present.xlsx\", \"4. spot curve\")\n",
    "\n",
    "#Test the different types of machine learning models on the data\n",
    "ridge_model_train_and_test, rf_model_train_and_test, xgb_model_train_and_test = train_and_test_ridge_rf_xgb(data)\n",
    "\n",
    "#Get the whole data to be used to train the machine learning models\n",
    "full_training_values = (\n",
    "    data['Time'].values,\n",
    "    data['Maturity'].values,\n",
    "    data['Rate'].values\n",
    ")\n",
    "\n",
    "#Train the multivariate function interest rate = f(time, maturity) \n",
    "multivariate_model = model_multivariate_function(values=full_training_values, s=len(full_training_values[2])/150)\n",
    "\n",
    "#Calculate and add the partial derivatives of the multivariate model to the data \n",
    "partial_time, partial_maturity = calculate_partial_derivatives(multivariate_model, data, 'Time', 'Maturity')\n",
    "data = add_partial_derivatives(data, (partial_time, partial_maturity))\n",
    "\n",
    "#Train the machine learning models on all the data\n",
    "ridge_model, rf_model, xgb_model = train_models_all_data(data, ['Time', 'Maturity', 'Rate_lag_1', 'Rate_lag_5', 'Rate_lag_20', 'Rate_rolling_mean_5', 'Rate_rolling_std_20', 'Partial_Derivative_Time', 'Partial_Derivative_Maturity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframe where the forecasts will be stored\n",
    "future_df = create_future_dataframe(past_data=data, multivariate_model=multivariate_model, days_ahead=365)\n",
    "\n",
    "#Forecast the future using the machine learning models trained on all the data\n",
    "future_using_ridge = predict_future_rates(ML_model=ridge_model, past_data=data, future_data=future_df.copy(), future_days=365, feature_columns=['Time', 'Maturity', 'Rate_lag_1', 'Rate_lag_5', 'Rate_lag_20', 'Rate_rolling_mean_5', 'Rate_rolling_std_20', 'Partial_Derivative_Time', 'Partial_Derivative_Maturity'])\n",
    "future_using_rf = predict_future_rates(ML_model=rf_model, past_data=data, future_data=future_df.copy(), future_days=365, feature_columns=['Time', 'Maturity', 'Rate_lag_1', 'Rate_lag_5', 'Rate_lag_20', 'Rate_rolling_mean_5', 'Rate_rolling_std_20', 'Partial_Derivative_Time', 'Partial_Derivative_Maturity'])\n",
    "future_using_xgb = predict_future_rates(ML_model=xgb_model, past_data=data, future_data=future_df.copy(), future_days=365, feature_columns=['Time', 'Maturity', 'Rate_lag_1', 'Rate_lag_5', 'Rate_lag_20', 'Rate_rolling_mean_5', 'Rate_rolling_std_20', 'Partial_Derivative_Time', 'Partial_Derivative_Maturity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the different forecasts in the original excel format\n",
    "clean_forecast_ridge = get_clean_forecasts(data, future_using_ridge)\n",
    "print(clean_forecast_ridge)\n",
    "\n",
    "clean_forecast_rf = get_clean_forecasts(data, future_using_rf)\n",
    "print(clean_forecast_rf)\n",
    "\n",
    "clean_forecast_xgb = get_clean_forecasts(data, future_using_xgb)\n",
    "print(clean_forecast_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32644261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the yield curve forecasted by ridge model at different dates\n",
    "plot_yield_curve_evolution(clean_forecast_ridge)\n",
    "\n",
    "#Plot 3d surface of the forecast\n",
    "plot_3d_yield_surface(clean_forecast_ridge)\n",
    "\n",
    "#Plot the time series for specific maturities\n",
    "plot_rate_time_series(clean_forecast_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the yield curve forecasted but random forest model at different dates\n",
    "plot_yield_curve_evolution(clean_forecast_rf)\n",
    "\n",
    "#Plot 3d surface of the forecast\n",
    "plot_3d_yield_surface(clean_forecast_rf)\n",
    "\n",
    "#Plot the time series for specific maturities\n",
    "plot_rate_time_series(clean_forecast_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612097e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the yield curve forecasted by xgb model at different dates\n",
    "plot_yield_curve_evolution(clean_forecast_xgb)\n",
    "\n",
    "#Plot 3d surface of the forecast\n",
    "plot_3d_yield_surface(clean_forecast_xgb)\n",
    "\n",
    "#Plot the time series for specific maturities\n",
    "plot_rate_time_series(clean_forecast_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
